{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Inteligencia Artificial y Aprendizaje </center> \n",
    "## <center> Práctica 3 </center> \n",
    "#### <center> *Ana San Román Gaitero y María González García* </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import seaborn as sbn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV,validation_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import export_graphviz\n",
    "#from sklearn.externals.six import StringIO  \n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la base de datos\n",
    "db = pd.read_csv('pima_indian_diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento Missing values \n",
    "\n",
    "db['Glucose'] = db['Glucose'].replace(0, np.nan)\n",
    "db['BloodPressure'] = db['BloodPressure'].replace(0, np.nan)\n",
    "db['SkinThickness'] = db['SkinThickness'].replace(0, np.nan)\n",
    "db['Insulin'] = db['Insulin'].replace(0, np.nan)\n",
    "db['BMI'] = db['BMI'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers\n",
    "def outliers (datos):\n",
    "    count=0\n",
    "    lista=[]\n",
    "    for i in db[datos]:\n",
    "        if not (db[datos].mean()-2.5*db[datos].std())<=i<=(db[datos].mean()+2.5*db[datos].std()):\n",
    "            if not np.isnan(i):\n",
    "                count=count+1\n",
    "                lista.append(i)\n",
    "   \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in db:\n",
    "    db[[i]]=db[[i]].replace(outliers(i),np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                  14\n",
      "Glucose                       7\n",
      "BloodPressure                52\n",
      "SkinThickness               231\n",
      "Insulin                     391\n",
      "BMI                          20\n",
      "DiabetesPedigreeFunction     20\n",
      "Age                          21\n",
      "Outcome                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(db.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.fillna(np.mean(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    268\n",
       "0    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanceo de los datos \n",
    "\n",
    "# Separación de la clase mayoritaria (no diabéticos) de la clase minoritaria (diabéticos)\n",
    "\n",
    "db_majority = db[db.Outcome==0]\n",
    "db_minority = db[db.Outcome==1]\n",
    " \n",
    "# Downsample majority class\n",
    "db_majority_downsampled = resample(db_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=268,     # to match minority class\n",
    "                                 random_state=2) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "db = pd.concat([db_majority_downsampled, db_minority])\n",
    " \n",
    "# Display new class counts\n",
    "db.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 8)\n",
      "(536,)\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos X e Y las separamos\n",
    "\n",
    "X = db.drop(['Outcome'], axis = 1)     # elimina la variable Outcome\n",
    "Y = db['Outcome']\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el conjunto de datos en los conjuntos de train y test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      183.000000\n",
       "305    120.000000\n",
       "630    114.000000\n",
       "319    194.000000\n",
       "522    114.000000\n",
       "          ...    \n",
       "577    118.000000\n",
       "72     126.000000\n",
       "661    121.687254\n",
       "749    162.000000\n",
       "7      115.000000\n",
       "Name: Glucose, Length: 375, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Glucose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      1\n",
       "305    0\n",
       "630    1\n",
       "319    1\n",
       "522    0\n",
       "      ..\n",
       "577    1\n",
       "72     1\n",
       "661    1\n",
       "749    1\n",
       "7      0\n",
       "Name: Outcome, Length: 375, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos después de haberlos separado en Train y Test\n",
    "\n",
    "X_norm = preprocessing.scale(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "print(X_train_norm.shape)\n",
    "print(X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN\n",
    "**Considere la normalización de características del espacio original de entrada al modelo. Justifique el tipo de normalización considerada y explique cómo lo realiza sobre cada subconjunto (entrenamiento, validación y test).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se considera la normalización estandar, ya que transforma los datos a una distribución más sencilla y más conocida. Dejando a todas las características con la misma media 0 y varianza 1. \n",
    "\n",
    "La función *StandardScaler* calcula la media y la desviación a partir de los datos del conjunto de training. Mediante esos estadísticos se realiza la normalización tanto en el conjunto de entrenamiento como en el de test. Además, la normalización se aplica de forma independiente para cada característica. Como el conjunto de validación procede del conjunto de train, al utilizar éste posteriormente en cross validation, ya estará normalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indique si las prestaciones obtenidas en el conjunto de test cambian tras normalizar las variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values=range(1,31,2)\n",
    "cv_k_scores=[]\n",
    "\n",
    "for k in k_values:\n",
    "    kNN=KNeighborsClassifier(n_neighbors=k) #clasificador knn\n",
    "    scores= cross_val_score(kNN, X_train, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador knn en train y 3 folds\n",
    "    cv_k_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(k_values, cv_k_scores)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seleccionamos el máximo valor porque estamso considerando entropía\n",
    "print(\"El valor de k más adecuado es\",np.array(k_values)[cv_k_scores.index(np.array(cv_k_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 17)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = KNN.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(Y_test, y_pred))\n",
    "print(\"Sensibility: \",recall_score(Y_test, y_pred))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "print(\"Specificity: \",confusion_matrix(Y_test, y_pred)[0][0]/(confusion_matrix(Y_test, y_pred)[0][0]+confusion_matrix(Y_test, y_pred)[0][1]))\n",
    "print(\"Precision:\", precision_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalizando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values=range(1,31,2)\n",
    "cv_k_scores=[]\n",
    "\n",
    "for k in k_values:\n",
    "    kNN=KNeighborsClassifier(n_neighbors=k) #clasificador knn\n",
    "    scores= cross_val_score(kNN, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador knn en train y 3 folds\n",
    "    cv_k_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(k_values, cv_k_scores)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seleccionamos el máximo valor porque estamso considerando entropía\n",
    "print(\"El valor de k más adecuado es\",np.array(k_values)[cv_k_scores.index(np.array(cv_k_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_norm = KNeighborsClassifier(n_neighbors = 15)\n",
    "kNN_norm.fit(X_train_norm, Y_train)\n",
    "\n",
    "y_pred1 = kNN_norm.predict(X_test_norm)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred1))\n",
    "print('Sensibility:',recall_score(Y_test, y_pred1))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_pred1))\n",
    "print('Specificity:',confusion_matrix(Y_test, y_pred1)[0][0]/(confusion_matrix(Y_test, y_pred1)[0][0]+confusion_matrix(Y_test, y_pred1)[0][1]))\n",
    "print(\"Precision:\", precision_score(Y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla = pd.DataFrame({ \"Prestaciones\":[\"Accuracy\",\"Sensibility\", 'Specificity','Precision'],\n",
    "                      \"kNN sin normalizar k=17\" : [\"0.72\",\"0.80\", '0.637','0.69'],\n",
    "                      \"kNN normalizado k=15\" : [\"0.733\",\"0.78\", '0.6875','0.72']})\n",
    "Tabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizando y sin normalizar las variables se obtienen distintos valores óptimos de k. Cuando k=17 (sin normalizar) se obtiene un accuracy, precisión y especificidad ligeramente menor y por el contrario, una sensibilidad mayor. Se podría entender que es mejor no normalizar los datos para detectar mejor a los casos diabéticos, pero al calcular distancias euclídeas es indispensable la normalización, ya que sin ella los resultados obtenidos no se ajustarían a la realidad, pues se encuentran en diferentes rangos dinámicos. Es por ello, que con un k=15 la sensibilidad, aunque sea ligeramente menor, es mucho más fiable (hay una precisión mayor). Es decir, tiene una mayor seguridad de detectar correctamente a los diabéticos.\n",
    "\n",
    "En conclusión, se obtienen mejores resultados en el conjunto de test tras haber normalizado las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explique razonadamente la relación entre la capacidad de generalización y el valor de k. Incluya las curvas de obtenidas para una medida de evaluación considerada tanto para el conjunto de train como para el de validación en función del parámetro k. Coméntelas brevemente.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de k influye significativamente en la capacidad de generalización del algoritmo. Un valor de k pequeño producirá fronteras altamente complejas y flexibles, sobreajustando el clasificador. Un valor de k grande puede dar lugar a fronteras demasiado suaves que no generalicen adecuadamente el modelo. Por lo tanto, es muy importante la correcta elección del valor de k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score, val_score = validation_curve(KNeighborsClassifier(), X_train_norm, Y_train,\n",
    "                                          'n_neighbors', k_values, cv=3)\n",
    "\n",
    "plt.plot(k_values, np.mean(train_score, 1), color='blue', label='Training accuracy')\n",
    "plt.plot(k_values, np.mean(val_score, 1), color='red', label='Validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1.2)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de entrenamiento sigue un comportamiento descendente hasta que llega a un punto que se estabiliza. Con valores pequeños de k se consigue un mayor accuracy, pues el modelo se esta diseñando en base a los datos de entrenamiento y las fronteras se ajustan perfectamente a dichos datos. Sin embargo, cada vez que k se va haciendo más grande, el accuracy se va haciendo más pequeño porque las fronteras se van volviendo más suaves, no ajustandose tan bien a los datos.\n",
    "\n",
    "Por otro lado, la curva de validación sigue un comportamiento contrario a la curva de entrenamiento. Al calcular el accuracy del conjunto de validación en un modelo demasiado flexible, con un valor de k pequeño, no se clasificaría correctamente ya que dicho modelo ha memorizado los datos del conjunto de entrenamiento. A medida que k aumenta, el accuracy va mejorando ya que el modelo ha conseguido fronteras que generalizan mejor y no memorizan los datos de entrenamiento, hasta que el valor de k es demasiado grande donde empieza a subajustar y no clasifica correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión\n",
    "\n",
    "**Indique si las prestaciones obtenidas en el conjunto de test cambian tras normalizar las variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "param_grid = { 'criterion':['gini','entropy']}\n",
    "\n",
    "# Creamos un árbol de clasificación\n",
    "dtree_model=tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Usamos gridsearch para evluar los parámetros\n",
    "dtree_model = GridSearchCV(dtree_model, param_grid, cv=3)\n",
    "\n",
    "# Entrenamos con los datos de train\n",
    "dtree_model=dtree_model.fit(X_train, Y_train)\n",
    "print(dtree_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = np.arange(1, 21)\n",
    "cv_depth_scores=[]\n",
    "for k in max_depth:\n",
    "    dtree = tree.DecisionTreeClassifier(max_depth = k, random_state=1) #clasificador knn\n",
    "    scores= cross_val_score(dtree, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador knn en train y 3 folds\n",
    "    cv_depth_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(max_depth, cv_depth_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seleccionamos el máximo valor porque estamso considerando entropía\n",
    "print(\"El valor de profundidad más adecuado es \",np.array(max_depth)[cv_depth_scores.index(np.array(cv_depth_scores).max())])\n",
    "print(\"El Accuracy es de\", max(cv_depth_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "my_model = tree.DecisionTreeClassifier(random_state=1, max_depth = 4)\n",
    "my_tree=my_model.fit(X_train, Y_train)\n",
    "\n",
    "#Predeccimos usando X_test\n",
    "y_predicted = my_tree.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "print('Accuracy:',accuracy_score(Y_test, y_predicted))\n",
    "print('Sensibility:',recall_score(Y_test, y_predicted))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_predicted)) \n",
    "print('Specificity:',confusion_matrix(Y_test, y_predicted)[0][0]/(confusion_matrix(Y_test, y_predicted)[0][0]+confusion_matrix(Y_test, y_predicted)[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalizando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_depthnorm_scores=[]\n",
    "for k in max_depth:\n",
    "    dtree = tree.DecisionTreeClassifier(random_state=1, max_depth = k) #clasificador knn\n",
    "    scores= cross_val_score(dtree, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador knn en train y 3 folds\n",
    "    cv_depthnorm_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(max_depth, cv_depthnorm_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seleccionamos el máximo valor porque estamso considerando entropía\n",
    "print(\"El valor de profundidad más adecuado es \",np.array(max_depth)[cv_depthnorm_scores.index(np.array(cv_depthnorm_scores).max())])\n",
    "print(\"El Accuracy es de\", max(cv_depthnorm_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "my_model_norm = tree.DecisionTreeClassifier(random_state=1, max_depth = 4)\n",
    "my_tree_norm=my_model_norm.fit(X_train_norm, Y_train)\n",
    "\n",
    "#Predeccimos usando X_test\n",
    "y_predicted = my_tree_norm.predict(X_test_norm)\n",
    "\n",
    "# Resultados\n",
    "print('Accuracy:',accuracy_score(Y_test, y_predicted))\n",
    "print('Sensibility:',recall_score(Y_test, y_predicted))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_predicted))\n",
    "print('Specificity:',confusion_matrix(Y_test, y_predicted)[0][0]/(confusion_matrix(Y_test, y_predicted)[0][0]+confusion_matrix(Y_test, y_predicted)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla1=pd.DataFrame({ \"Prestaciones\":[\"Accuracy\",\"Sensibility\", 'Specificity'],\n",
    "                      \"Árbol sin normalizar\" : [\"0.73\",\"0.73\", '0.74'],\n",
    "                      \"Árbol normalizado\" : [\"0.73\",\"0.73\", '0.74']})\n",
    "Tabla1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que las prestaciones en el conjunto de test tras normalizar las variables no han cambiado, como era de esperar. Esto es debido a que, de forma recursiva, se va a dividir el espacio en regiones, escogiendo cada vez una variable distinta. Por lo que, cada decisión es independiente a la anterior y por tanto, da igual tener variables en diferentes rangos dinámicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En términos de subajuste y sobreajuste, explique cuál de ellos es más probable que ocurra si el máximo número de casos por nodo del árbol es muy pequeño. Probarlo.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se calcula el valor óptimo para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_samples_split = np.arange(2,256)\n",
    "cv_nodo_scores=[]\n",
    "for k in min_samples_split:\n",
    "    dtree = tree.DecisionTreeClassifier(random_state=1, min_samples_split=k) #clasificador knn\n",
    "    scores= cross_val_score(dtree, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador knn en train y 3 folds\n",
    "    cv_nodo_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(min_samples_split, cv_nodo_scores)\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seleccionamos el máximo valor porque estamso considerando entropía\n",
    "print(\"El valor de casos para dividir un nodo más adecuado es \",np.array(min_samples_split)[cv_nodo_scores.index(np.array(cv_nodo_scores).max())])\n",
    "print(\"El Accuracy es de\", max(cv_nodo_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En gráfica se observa como los valores más altos previenen que el modelo “memorice”. Pero cuando supera la cantidad de datos de los dos fold que utiliza para diseñar el modelo, el accuracy disminuye drásticamente, ya que el árbol no puede separar el nodo raiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min número casos nodo pequeño vs min número óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo con el valor óptimo\n",
    "my_model_norm = tree.DecisionTreeClassifier(random_state=1,min_samples_split=143)\n",
    "my_tree_norm=my_model_norm.fit(X_train_norm, Y_train)\n",
    "\n",
    "#Predeccimos usando X_test\n",
    "y_predicted = my_tree_norm.predict(X_test_norm)\n",
    "\n",
    "# Prestaciones en el conjunto de test\n",
    "print('Accuracy:',accuracy_score(Y_test, y_predicted))\n",
    "print('Sensibility:',recall_score(Y_test, y_predicted))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_predicted))\n",
    "print('Specificity:',confusion_matrix(Y_test, y_predicted)[0][0]/(confusion_matrix(Y_test, y_predicted)[0][0]+confusion_matrix(Y_test, y_predicted)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo con un valor pequeño de casos por nodo\n",
    "my_model_norm = tree.DecisionTreeClassifier(random_state=1,min_samples_split=2)\n",
    "my_tree_norm=my_model_norm.fit(X_train_norm, Y_train)\n",
    "\n",
    "#Predeccimos usando X_test\n",
    "y_predicted = my_tree_norm.predict(X_test_norm)\n",
    "\n",
    "# Resultados\n",
    "print('Accuracy:',accuracy_score(Y_test, y_predicted))\n",
    "print('Sensibility:',recall_score(Y_test, y_predicted))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_predicted))\n",
    "print('Specificity:',confusion_matrix(Y_test, y_predicted)[0][0]/(confusion_matrix(Y_test, y_predicted)[0][0]+confusion_matrix(Y_test, y_predicted)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla1=pd.DataFrame({ \"Prestaciones\":[\"Accuracy\",\"Sensibility\", 'Specificity'], ############################\n",
    "                      \"min número casos nodo=143\" : [\"0.71\",\"0.72\", '0.7125'],\n",
    "                      \"min número casos nodo=2\" : [\"0.65\",\"0.68\", '0.6125']})\n",
    "Tabla1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al elegir un valor de *min_samples_split* muy pequeño (en este caso 2), el árbol sigue partiendo una región hasta que el número de casos que contenga sea igual a 2. Esto provoca que el árbol cree relaciones muy especificas y fronteras muy flexibles, obligando a que el algoritmo memorice en vez de aprender. Se concluye que se obtienen peores resultados cuando el mìnimo numero de casos para dividir un nodo es muy pequeño.\n",
    "\n",
    "Sin embargo, con un valor de *min_samples_split* = 143, elegido mediante cross validation, consigue generalizar mejor. Es por ello, que se obtienen mejores resultados en el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min número casos en el nodo terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_samples_leaf = range(1, 126)\n",
    "cv_leaf_scores=[]\n",
    "for k in min_samples_leaf:\n",
    "    dtree = tree.DecisionTreeClassifier(random_state=1,min_samples_leaf=k)\n",
    "    scores= cross_val_score(dtree, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    cv_leaf_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(min_samples_leaf, cv_leaf_scores)\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seleccionamos el máximo valor porque estamso considerando entropía\n",
    "print(\"El valor de casos en el nodo terminal más adecuado es \",np.array(min_samples_leaf)[cv_leaf_scores.index(np.array(cv_leaf_scores).max())])\n",
    "print(\"El Accuracy es de\", max(cv_leaf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se puede observar que valores grandes de *min_samples_leaf* predicen mejor que los valores pequeños. Pero cuando  la cantidad de datos es mayor a la que hay en cada fold (125) el accuracy disminuye drásticamente, ya que el árbol no puede tener un nodo terminal con un número menor a 125. Por ejemplo: si se parte de 250 muestras en el nodo raíz y se tiene un *min_samples_leaf*=126, el árbol se dividiría en dos nodos terminales, teniendo uno de ellos un número de casos terminales que no alcanzaría el mínimo, lo cual no podría dividirse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indique cuáles de los parámetros comentados en teoría ha analizado para conseguir que el modelo diseñado tenga capacidad de generalización.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conseguir que el modelo tenga capacidad de generalización se han analizado el mínimo número de muestras para dividir un nodo, el mínimo número de muestras para un nodo terminal y la máxima profundidad del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_norm = tree.DecisionTreeClassifier(random_state=1,max_depth=4,min_samples_split=143,min_samples_leaf=123)\n",
    "my_tree_norm=my_model_norm.fit(X_train_norm, Y_train)\n",
    "y_predicted=my_tree_norm.predict(X_test_norm)\n",
    "print('Accuracy:',accuracy_score(Y_test, y_predicted))\n",
    "print('Sensibility:',recall_score(Y_test, y_predicted))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_predicted))\n",
    "print('Specificity:',confusion_matrix(Y_test, y_predicted)[0][0]/(confusion_matrix(Y_test, y_predicted)[0][0]+confusion_matrix(Y_test, y_predicted)[0][1]))\n",
    "print(\"Precision:\", precision_score(Y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según los parámetros obtenidos con cross validation se obtiene el siguiente árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(my_tree_norm, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = db.columns[0:-1],class_names=['Diabetic','Non Diabetic'])\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene un árbol con profundidad 1, el mínimo número de casos en el nodo terminal igual a 123 y el mínimo número de casos para dividir un nodo igual a 143; que según las prestaciones obtenidas en validación y en test da buenos resultados, accuracy aproximadamente de 0'7. Sin embargo, teóricamente dichos valores de los parámetros estarían subajustando. Se aconsejaría realizar el proceso varias veces para diferentes particiones y balanceos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incluya las curvas de obtenidas para una medida de evaluación considerada tanto para el conjunto de train como para el de validación en función de cada parámetro. Coméntelas brevemente.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Profundidad del arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_depth=np.arange(2,21)\n",
    "\n",
    "train_score, val_score = validation_curve(tree.DecisionTreeClassifier(criterion='gini'), X_train_norm, Y_train,\n",
    "                                          'max_depth', max_depth, cv=3)\n",
    "\n",
    "plt.plot(max_depth, np.mean(train_score, 1), color='blue', label='Training accuracy')\n",
    "plt.plot(max_depth, np.mean(val_score, 1), color='red', label='Validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0.5, 1.1)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de entrenamiento sigue un comportamiento ascendente hasta que llega a un punto que se estabiliza. Con valores grandes de *max_depth* se consigue un mayor accuracy, pues el clasificador se esta diseñando en base a los datos de entrenamiento y esta creando relaciones específicas a dichos datos. Sin embargo, para valores pequeños, el accuracy es menor ya que el árbol no divide los nodos necesarios para definir a sus datos, por la limitación de su profundidad.\n",
    "\n",
    "Por otro lado, la curva de validación sigue un comportamiento contrario a la curva de entrenamiento. Teóricamente, esta curva debería tener una forma de U invertida, donde valores pequeños de profundidad subajustarían (accuracy bajo) y valores grandes de profundidad sobreajustarían obteniendo un accuracy bajo. Sin embargo, esto es muy difícil de ver en la práctica, por ello obtenemos una curva de validación que comienza con un accuracy bajo hasta 4, y luego sigue disminuyendo hasta que se estabiliza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Min número casos para dividir un nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_samples_split = np.arange(2,150)\n",
    "\n",
    "train_score, val_score = validation_curve(tree.DecisionTreeClassifier(random_state=1), X_train_norm, Y_train,\n",
    "                                          'min_samples_split', min_samples_split, cv=3)\n",
    "\n",
    "plt.plot(min_samples_split, np.mean(train_score, 1), color='blue', label='Training accuracy')\n",
    "plt.plot(min_samples_split, np.mean(val_score, 1), color='red', label='Validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.xlabel('Min number samples')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de entrenamiento sigue un comportamiento descendente hasta que llega a un punto que se estabiliza. Con valores pequeños de *min_samples_split* se consigue un mayor accuracy, ya que se crea un árbol más específico y se ha creado a partir de los datos de entrenamiento. Sin embargo, para valores grandes, el accuracy es menor ya que el árbol no divide los nodos necesarios para definir a sus datos.\n",
    "\n",
    "Por otro lado, la curva de validación sigue un comportamiento ascendente hasta un determinado valor óptimo, a partir del cual desciende y se estabiliza. En esta curva se asemeja mejor al comportamiento teórico en comparación con la curva de validación de profundidad. Para valores grandes de *min_samples_split* subajusta y para valores pequeños sobreajusta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Min número casos para un nodo terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_samples_leaf = np.arange(1, 50)\n",
    "\n",
    "train_score, val_score = validation_curve(tree.DecisionTreeClassifier(random_state=1), X_train_norm, Y_train,\n",
    "                                          'min_samples_leaf', min_samples_leaf, cv=3)\n",
    "\n",
    "plt.plot(min_samples_leaf, np.mean(train_score, 1), color='blue', label='Training accuracy')\n",
    "plt.plot(min_samples_leaf, np.mean(val_score, 1), color='red', label='Validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de entrenamiento de *min_samples_leaf* sigue el mismo comportamiento que la de *min_samples_split*, teniendo las mismas razones que ésta al igual que la de validación. Para valores grandes de *min_samples_leaf* subajusta y para valores pequeños sobrejusta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón Multicapa\n",
    "\n",
    "**Haciendo uso de las características del conjunto de observaciones en el espacio original, diseñe un Perceptrón Multicapa (MLP) con una única capa oculta, inicialización aleatoria de los pesos de la red neuronal, aprendizaje en modo mini-batch (por mini-lotes), algoritmo de entrenamiento back- propagation y detención del aprendizaje haciendo uso de la técnica “early stopping”.\n",
    "Justifique razonadamente:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El número de neuronas de entrada al MLP:\n",
    "\n",
    "El número de neuronas de entrada al MLP será igual al número de carcaterísticas que tengamos en la base de datos (Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age) en este caso, 8 neuronas de entrada. \n",
    "\n",
    "- El número de neuronas de salida del MLP.\n",
    "\n",
    "Al tener una variable de salida binaria (Outcome), el número de neuronas de salida del MLP será 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las funciones de activación consideradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_act=[\"logistic\",\"tanh\",\"relu\"]\n",
    "cv_act_scores=[]\n",
    "for k in cv_act:\n",
    "    MLP = MLPClassifier(random_state=1,max_iter=5000, activation=k)\n",
    "    scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    print('Score',scores)\n",
    "    cv_act_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "\n",
    "plt.plot(cv_act, cv_act_scores)\n",
    "plt.xlabel('Función de activación')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(\"La función de acivación más adecuada es:\",np.array(cv_act)[cv_act_scores.index(np.array(cv_act_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_act_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante cross validation se observa que la función de activación que mejor accuracy presenta en el conjunto de validación es *logistic*. Por tanto, se elige para crear el clasificador MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prestaciones en el conjunto de test\n",
    "MLP = MLPClassifier(random_state=1, activation=\"logistic\",max_iter=5000) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El valor de la tasa de aprendizaje utilizada, así como variación (o no) de la misma durante el aprendizaje.\n",
    "\n",
    "El tipo de tasa de aprendizaje o *learning_rate* solo es aplicable para el descenso del gradiente. Por ello, para calcular estos parametros de tasa de aprendizaje, primero es necesario ver que solver es el más indicado en nuestro modelo MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver=[\"lbfgs\", \"sgd\", \"adam\"]\n",
    "cv_sol_scores=[]\n",
    "\n",
    "for k in solver:\n",
    "    MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=k)\n",
    "    scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador MLP en train y 3 folds\n",
    "    print('Score',scores)\n",
    "    cv_sol_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "\n",
    "    \n",
    "plt.plot(solver, cv_sol_scores)\n",
    "plt.xlabel('Solver')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"El solver más adecuado es:\",np.array(solver)[cv_sol_scores.index(np.array(cv_sol_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_sol_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante cross validation se observa que los solver que mejor accuracy presentan en el conjunto de validación son *sgd* y *adam*. Por tanto, se elige *sgd* para crear el clasificador MLP debido a que *adam* principalmente se utiliza para grandes bases de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, activation=\"logistic\",max_iter=5000, solver=\"sgd\") \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el solver es sgd, debemos calcular el learning rate y learning rate init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate=[\"constant\", \"adaptive\", \"invscaling\"]\n",
    "cv_rate_scores=[]\n",
    "\n",
    "for k in learning_rate:\n",
    "    MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver='sgd',learning_rate=k)\n",
    "    scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador MLP en train y 3 folds\n",
    "    print('Score',scores)\n",
    "    cv_rate_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "plt.plot(learning_rate, cv_rate_scores)\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"El learning_rate más adecuado es:\",np.array(learning_rate)[cv_rate_scores.index(np.array(cv_rate_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_rate_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la tasa de aprendizaje no variará a medida que desciende el gradiente. Normalmente, en la mayoria de los casos, es mejor una tasa de aprendizaje adaptativa, es decir, que vaya muy rápido al principio y cuando se acerque al mínimo global disminuya para no saltárselo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, activation=\"logistic\",max_iter=5000, solver=\"sgd\", learning_rate='constant') \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Learning rate init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculo del parámetro learning_rate_init sobre el conjunto de validación \n",
    "\n",
    "learning_rate_init = np.linspace(0.0009,0.1)\n",
    "cv_learning_scores=[]\n",
    "\n",
    "for k in learning_rate_init:\n",
    "    \n",
    "    MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=k )\n",
    "    scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador MLP en train y 3 folds\n",
    "    #print('Score',scores)\n",
    "    cv_learning_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "\n",
    "    \n",
    "plt.plot(learning_rate_init, cv_learning_scores)\n",
    "plt.xlabel('learning_rate_init')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"El tasa de aprendizaje más adecuado es:\",np.array(learning_rate_init)[cv_learning_scores.index(np.array(cv_learning_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_learning_scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en la gráfica, con valores pequeños se consigue llegar a un mayor accuracy ya que va poco a poco sin saltarse el mínimo global, sin embargo, tiene un mayor coste computacional en cuanto al tiempo. Con valores grandes, en torno a 0.06, el accuracy comienza a disminuir porque la tasa de aprendizaje se salta el mínimo global y llega a un mínimo local de la función de coste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluación de las prestaciones en el conjunto de test\n",
    "\n",
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init= 0.0029224489795918367) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Función de coste a optimizar.\n",
    "\n",
    "La función de coste elegida es Cross Entropy ya que contamos con un problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los valores numéricos que representan el número de neuronas consideradas en la capa oculta. Justifique la consideración de cada uno de los valores indicados (al menos, tres valores:n_hidden_1, n_hidden_2 y n_hidden_3).\n",
    "\n",
    "El número de neuronas en la capa ocula es un parámetro a elegir por medio de cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo del parámetro de número de neuronas en la capa oculta sobre el conjunto de validación \n",
    "neuronas = []\n",
    "for i in range(1,80):\n",
    "    neuronas.append((i,))\n",
    "\n",
    "cv_neu_scores=[]\n",
    "\n",
    "for k in neuronas:\n",
    "    \n",
    "    MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init= 0.0029224489795918367,hidden_layer_sizes=k)\n",
    "    scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador MLP en train y 3 folds\n",
    "    #print('Score',scores)\n",
    "    cv_neu_scores.append(scores.mean()) #almacena la media de los scores\n",
    "       \n",
    "plt.plot(neuronas, cv_neu_scores)\n",
    "plt.xlabel('neuronas')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"El numero de neuronas más adecuado es:\",np.array(neuronas)[cv_neu_scores.index(np.array(cv_neu_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_neu_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de pesos se incrementará cuantas más neuronas haya en la capa oculta generando un modelo más complejo. Esto produce que el clasificador sea menos lineal y por lo tanto, cueste más llegar a una solución óptima (mínimo global). En la gráfica, cuanto mayor se va haciendo el número de neuronas, los picos ya no llegan a los valores de accuracy que se obtenían con los valores pequeños de neuronas. Es por ello, que se obtiene un valor de 29 neuronas en la capa oculta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluación de las prestaciones en el conjunto de test\n",
    "\n",
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init= 0.0029224489795918367,hidden_layer_sizes=(29,)) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentaje de observaciones consideradas al aplicar la técnica “early stopping”. Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init= 0.0029224489795918367,hidden_layer_sizes=(29,),early_stopping=True,verbose=True)\n",
    "scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "#print('Score',scores)\n",
    "#cv_neu_scores.append(scores.mean()) #almacena la media de los scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizamos *early stopping* en el clasificador, mediante el parámetro *verbose* se puede observar que en cada fold para en la época 12, ya que la función de pérdida no disminuye en las dos últimas iteraciones. Por lo que considera que está muy cerca del mínimo global y de esta forma no sobreajusta. Sin embargo, se observa que el accuracy obtenido es muy bajo (0.48), por lo que se podría pensar que lo que el *early stopping* considera como un mínimo global en realidad es un mínimo local. Por tanto, sería necesario modificar el valor del parametro *momentum*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,), early_stopping=True) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Matriz de confusión:')\n",
    "print(confusion_matrix(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por todo lo explicado anteriormente, se puede observar como el clasificador no detecta correctamente las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamaño del mini-batch. Opcional\n",
    "\n",
    "Batch es el número de datos que tiene cada iteración de una época, esto es útil porque la red neuronal actualiza los parámetros de los pesos más veces, consiguiendo caracterizar mejor a la población, además de que ayuda computacionalmente a que vaya más rápido. \n",
    "\n",
    "\n",
    "Se considera un parámetro libre, con lo que por medio de cross validation se consigue el tamaño óptimo del batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = range(10,100)##\n",
    "cv_batch_scores=[]\n",
    "for k in batch:\n",
    "    \n",
    "    MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,),batch_size=k )\n",
    "    scores= cross_val_score(MLP, X_train_norm, Y_train, cv=3, scoring='accuracy') \n",
    "    #calcula el accuracy con el clasificador MLP en train y 3 folds\n",
    "    #print('Score',scores)\n",
    "    cv_batch_scores.append(scores.mean()) #almacena la media de los scores\n",
    "    \n",
    "\n",
    "    \n",
    "plt.plot(batch, cv_batch_scores)\n",
    "plt.xlabel('batch')\n",
    "plt.ylabel('CV accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"El número de batch más adecuado es:\",np.array(batch)[cv_batch_scores.index(np.array(cv_batch_scores).max())])\n",
    "print(\"Accuracy:\", max(cv_batch_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,),batch_size=63) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si hace uso o no (y por qué) de aleatorización de las observaciones durante el aprendizaje. Opcional\n",
    "\n",
    "Para caracterizar mejor a la población, se hace uso de shuffle para aleatorizar las observaciones en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,),batch_size=63, shuffle=False) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,),batch_size=63, shuffle=True) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto shuffle = True, con lo que se obtienen mejores prestaciones aleatorizando las observaciones en cada época. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Número máximo de épocas. Explique de manera breve y concisa qué es una época, ejemplificando con su caso particular.\n",
    "\n",
    "Una época es el número de veces que se ejecutaran los algoritmos de forwardpropagation y backpropagation. En cada época  todos los datos de entrenamiento pasan por la red neuronal para que esta aprenda sobre ellos. Por ejemplo, en este caso, al usar 5000 ciclos o épocas y 375 datos de entrenamiento, en cada ciclo los 375 datos pasaran por la red neuronal.\n",
    "\n",
    "Hemos utilizado un *max_iter* de 5000 épocas en el cálculo de cada uno de los parámetros para que converja la función de coste. Sin embargo, con el clasificador ya definido con todos los parámetros óptimos no se necesitan tantas épocas para converger. Esto se puede ver con el parámetro *verbose* a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=5000, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,),batch_size=63, verbose = True) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred))\n",
    "print('Sensibility',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se comentaba arriba, se puede observar con este resultado  que para que la función de coste converja no son necesarias tantas iteraciones ya que se logra con muchas menos, en este caso 307. Esto se ve mediante la función de pérdida ya que llega a un punto en el que no sigue disminuyendo, y ese punto es en la época 307."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=1, max_iter=307, activation=\"logistic\", solver=\"sgd\",learning_rate='constant',learning_rate_init=0.0029224489795918367,hidden_layer_sizes=(29,),batch_size=63) \n",
    "\n",
    "MLP_model=MLP.fit(X_train_norm, Y_train)\n",
    "y_pred1=MLP_model.predict(X_test_norm)\n",
    "print('Accuracy:', accuracy_score(Y_test, y_pred1))\n",
    "print('Sensibility',recall_score(Y_test, y_pred1))\n",
    "print(\"Confusión matrix: \")\n",
    "print(confusion_matrix(Y_test, y_pred1))\n",
    "print('Specificity:',confusion_matrix(Y_test, y_pred1)[0][0]/(confusion_matrix(Y_test, y_pred1)[0][0]+confusion_matrix(Y_test, y_pred1)[0][1]))\n",
    "print(\"Precision:\", precision_score(Y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realice el aprendizaje de todas las topologías, i.e., considerando al menos n_hidden_1, n_hidden_2 y n_hidden_3 neuronas en la capa oculta. Elija varias medidas de prestaciones (adecuadas para la tarea a resolver) y construya una tabla indicando, para cada topología del MLP, dichas prestaciones sobre el conjunto de validación.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada nuevo parámetro del clasificador MLP se ha ido acumulando la mejor opción del anterior, excepto para el parámetro *early stopping* que por sus malos resultados, no se ha utilizado en las siguientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla1 = pd.DataFrame({ \"Prestaciones en el conjunto de validacion\":[\"Accuracy\"],\n",
    "                      \"activation = logistic\" : [\"0.731\"],\n",
    "                      \"solver = sgd\" : [\"0.731\"],\n",
    "                       \"learning_rate = constant\": [\"0.731\"],\n",
    "                    \"learning_rate_init=0.0029\" : [\"0.739\"],\n",
    "                     \"hidden_layer_sizes=29\" : [\"0.749\"],\n",
    "                       \"early_stopping=True\" : [\"0.48\"]})\n",
    "Tabla1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy se mantiene constante en los tres primeros parámetros, esto se debe a que éstos son los default. A partir de *learning rate init* el accuracy va aumentando. Este aumento se debe a que los parámetros han sido elegidos uno a uno, mediante cross validation, y van ajustando mejor el modelo. Lo siguiente que se puede observar es que el parámetro *early stopping* disminuye significativamente el accuracy por lo comentado anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justifique razonadamente la elección de una topología y obtenga las prestaciones sobre el conjunto de test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabla1 = pd.DataFrame({ \"Prestaciones en el conjunto de test\":[\"Accuracy\",\"Sensibility\"],\n",
    "                      \"activation = logistic\" : [\"0.739\",\"0.716\"],\n",
    "                      \"solver = sgd\" : [\"0.739\",\"0.704\"],\n",
    "                       \"learning_rate = constant\": [\"0.739\",\"0.704\"],\n",
    "                    \"learning_rate_init=0.0029\" : [\"0.739\",\"0.716\"],\n",
    "                     \"hidden_layer_sizes=29\" : [\"0.732\",\"0.704\"],\n",
    "                       \"early_stopping=True\" : [\"0.503\",\"-\"],\n",
    "                      \"batch = 63\": [\"0.745\", \"0.716\"]})\n",
    "Tabla1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se perciben leves diferencias en el accuracy y la sensibilidad modificando los distintos parámetros elegidos con cross validation. Es cierto, que en validación observamos que el accuracy va aumentando a medida que se van implementando más parámetros. Sin embargo, en test no tienen por que reflejarse las mismas mejoras. Si se realizara otra partición con un conjunto de test diferente, las prestaciones mejorarían o empeorarían. Por tanto, las prestaciones dependen mucho del conjunto de test y por ello, sería aconsejable repetir el proceso y reflejar las prestaciones como la media ± desviación estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de resultados\n",
    "\n",
    "**A la vista de los resultados obtenidos para resolver la tarea de clasificación planteada, justifique brevemente qué modelo considera más adecuado.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prestaciones</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Árbol de decisión</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sensibility</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prestaciones    KNN Árbol de decisión    MLP\n",
       "0     Accuracy  0.733             0.720  0.745\n",
       "1  Sensibility  0.778             0.753  0.716\n",
       "2  Specificity  0.637             0.688  0.775\n",
       "3    Precision  0.691             0.709  0.763"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tabla1 = pd.DataFrame({ \"Prestaciones\":[\"Accuracy\",\"Sensibility\",'Specificity','Precision'],\n",
    "                      \"KNN\" : [\"0.733\",\"0.778\",'0.637','0.691'],\n",
    "                      \"Árbol de decisión\" : [\"0.720\",\"0.753\",'0.688','0.709'],\n",
    "                    \"MLP\" : [\"0.745\",\"0.716\",'0.775','0.763']})\n",
    "Tabla1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A una primera vista MLP es el modelo que mejor se ajusta a nuestros datos, dado que presenta un mayor accuracy, el cual es la cantidad de casos detectados correctamente. Además de destacar en especificidad y en precisión, lo cual significa que detecta muy bien a los no diabéticos y que cuando detecta a los diabéticos lo hace con seguridad.\n",
    "Sin embargo, el clasificador kNN y el árbol de decisión tienen una mayor sensibilidad, es decir, detectan mejor a los casos positivos como realmente enfermos (diabéticos)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
